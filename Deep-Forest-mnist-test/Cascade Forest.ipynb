{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from mnist import MNIST\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ETC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "N_CLASSES = 10\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "mndata = MNIST(\"./data/\")\n",
    "images, labels = mndata.load_training()\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForestLayer:\n",
    "    def __init__(self, clfs):\n",
    "        self.clfs = clfs # list of classifiers\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        [clf.fit(X, y) for clf in self.clfs]\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        return [clf.predict_proba(X) for clf in self.clfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cascadeForest:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers # list of classifiers\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        acc_arr = []\n",
    "        X_new = np.copy(X)\n",
    "        acc_old = 0\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer.train(X_new,y)\n",
    "            pred = layer.predict_proba(X_new)\n",
    "            \n",
    "            ## verbose\n",
    "            ave = np.average(np.array(pred), axis = 0)\n",
    "            predictions = np.argmax(ave, axis=1)\n",
    "            acc = accuracy_score(predictions, y)\n",
    "            acc_arr.append(acc)\n",
    "            print(\"Layer\",i+1,\"accuracy:\", acc)\n",
    "            ##\n",
    "            if acc<=acc_old:\n",
    "                break\n",
    "            acc_old=acc\n",
    "            \n",
    "            X_new = np.concatenate(pred, axis=1)\n",
    "            X_new = np.concatenate((X_new, X), axis=1)\n",
    "            \n",
    "    def predict_proba(self, X, y):\n",
    "        acc_arr = []\n",
    "        X_new = np.copy(X)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            pred = layer.predict_proba(X_new)\n",
    "            \n",
    "            ## verbose\n",
    "            ave = np.average(np.array(pred), axis = 0)\n",
    "            predictions = np.argmax(ave, axis=1)\n",
    "            acc = accuracy_score(predictions, y)\n",
    "            acc_arr.append(acc)\n",
    "            print(\"Layer\",i+1,\"accuracy:\", acc)\n",
    "            ##\n",
    "            \n",
    "            X_new = np.concatenate(pred, axis=1)\n",
    "            X_new = np.concatenate((X_new, X), axis=1)\n",
    "            \n",
    "        return np.average(np.array(pred), axis = 0), acc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 accuracy: 0.9154375\n",
      "Layer 2 accuracy: 0.9324583333333333\n",
      "Layer 3 accuracy: 0.939875\n",
      "Layer 4 accuracy: 0.9439583333333333\n",
      "Layer 5 accuracy: 0.9474791666666667\n",
      "Layer 6 accuracy: 0.9497291666666666\n",
      "Layer 7 accuracy: 0.9515625\n",
      "Layer 8 accuracy: 0.9534583333333333\n",
      "Layer 9 accuracy: 0.9556666666666667\n",
      "Layer 10 accuracy: 0.957875\n",
      "Layer 11 accuracy: 0.9599375\n",
      "Layer 12 accuracy: 0.9610208333333333\n",
      "Layer 13 accuracy: 0.9623125\n",
      "Layer 14 accuracy: 0.9639583333333334\n",
      "Layer 15 accuracy: 0.9657708333333334\n",
      "Layer 16 accuracy: 0.9669791666666666\n",
      "Layer 17 accuracy: 0.9679375\n",
      "Layer 18 accuracy: 0.9687708333333334\n",
      "Layer 19 accuracy: 0.96925\n",
      "Layer 20 accuracy: 0.9698125\n",
      "Layer 21 accuracy: 0.9710833333333333\n",
      "Layer 22 accuracy: 0.9722916666666667\n",
      "Layer 23 accuracy: 0.9731875\n",
      "Layer 24 accuracy: 0.9734166666666667\n",
      "Layer 25 accuracy: 0.9740625\n",
      "Layer 26 accuracy: 0.9747083333333333\n",
      "Layer 27 accuracy: 0.975375\n",
      "Layer 28 accuracy: 0.9759791666666666\n",
      "Layer 29 accuracy: 0.9765833333333334\n",
      "Layer 30 accuracy: 0.9770625\n",
      "Layer 31 accuracy: 0.9776041666666667\n",
      "Layer 32 accuracy: 0.978\n",
      "Layer 33 accuracy: 0.9782708333333333\n",
      "Layer 34 accuracy: 0.9785625\n",
      "Layer 35 accuracy: 0.9790416666666667\n",
      "Layer 36 accuracy: 0.9792708333333333\n",
      "Layer 37 accuracy: 0.97975\n",
      "Layer 38 accuracy: 0.9801875\n",
      "Layer 39 accuracy: 0.9805208333333333\n",
      "Layer 40 accuracy: 0.9808958333333333\n",
      "Layer 41 accuracy: 0.9812083333333333\n",
      "Layer 42 accuracy: 0.9816458333333333\n",
      "Layer 43 accuracy: 0.98175\n",
      "Layer 44 accuracy: 0.9820833333333333\n",
      "Layer 45 accuracy: 0.9823541666666666\n",
      "Layer 46 accuracy: 0.9824791666666667\n",
      "Layer 47 accuracy: 0.9830208333333333\n",
      "Layer 48 accuracy: 0.98325\n",
      "Layer 49 accuracy: 0.9836041666666666\n",
      "Layer 50 accuracy: 0.983875\n",
      "Layer 51 accuracy: 0.9841875\n",
      "Layer 52 accuracy: 0.9842916666666667\n",
      "Layer 53 accuracy: 0.9844166666666667\n",
      "Layer 54 accuracy: 0.9844791666666667\n",
      "Layer 55 accuracy: 0.9846458333333333\n",
      "Layer 56 accuracy: 0.9848958333333333\n",
      "Layer 57 accuracy: 0.9850416666666667\n",
      "Layer 58 accuracy: 0.9851666666666666\n",
      "Layer 59 accuracy: 0.9851875\n",
      "Layer 60 accuracy: 0.985375\n",
      "Layer 61 accuracy: 0.9855833333333334\n",
      "Layer 62 accuracy: 0.9858125\n",
      "Layer 63 accuracy: 0.986125\n",
      "Layer 64 accuracy: 0.9862083333333334\n",
      "Layer 65 accuracy: 0.9863541666666666\n",
      "Layer 66 accuracy: 0.9864583333333333\n",
      "Layer 67 accuracy: 0.9865208333333333\n",
      "Layer 68 accuracy: 0.9866666666666667\n",
      "Layer 69 accuracy: 0.9867291666666667\n",
      "Layer 70 accuracy: 0.9867708333333334\n",
      "Layer 71 accuracy: 0.9869375\n",
      "Layer 72 accuracy: 0.9870208333333333\n",
      "Layer 73 accuracy: 0.9871458333333333\n",
      "Layer 74 accuracy: 0.9873125\n",
      "Layer 75 accuracy: 0.9874583333333333\n",
      "Layer 76 accuracy: 0.9875625\n",
      "Layer 77 accuracy: 0.9875625\n"
     ]
    }
   ],
   "source": [
    "n_layers = 100 #max_num_layers\n",
    "layers = []\n",
    "for i in range(n_layers):thor\n",
    "    clfs = []\n",
    "    clfs.append( RFC(n_estimators=500, max_leaf_nodes = 100, n_jobs=6) )\n",
    "    clfs.append( RFC(n_estimators=500, max_leaf_nodes = 100, n_jobs=6) )\n",
    "    clfs.append( ETC(n_estimators=500, max_leaf_nodes = 100, n_jobs=6) )\n",
    "    clfs.append( ETC(n_estimators=500, max_leaf_nodes = 100, n_jobs=6) )\n",
    "    layers.append( ForestLayer(clfs) )\n",
    "\n",
    "cf = cascadeForest(layers)\n",
    "    \n",
    "# Train on the first 10000 images:\n",
    "train_x = images[:48000]\n",
    "train_y = labels[:48000]\n",
    "\n",
    "train_acc = cf.train(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 accuracy: 0.9239166666666667\n",
      "Layer 2 accuracy: 0.93275\n",
      "Layer 3 accuracy: 0.9360833333333334\n",
      "Layer 4 accuracy: 0.9388333333333333\n",
      "Layer 5 accuracy: 0.9405833333333333\n",
      "Layer 6 accuracy: 0.9419166666666666\n",
      "Layer 7 accuracy: 0.94325\n",
      "Layer 8 accuracy: 0.9435833333333333\n",
      "Layer 9 accuracy: 0.945\n",
      "Layer 10 accuracy: 0.94625\n",
      "Layer 11 accuracy: 0.9470833333333334\n",
      "Layer 12 accuracy: 0.94775\n",
      "Layer 13 accuracy: 0.9479166666666666\n",
      "Layer 14 accuracy: 0.9485\n",
      "Layer 15 accuracy: 0.9494166666666667\n",
      "Layer 16 accuracy: 0.9495\n",
      "Layer 17 accuracy: 0.9494166666666667\n",
      "Layer 18 accuracy: 0.9499166666666666\n",
      "Layer 19 accuracy: 0.95025\n",
      "Layer 20 accuracy: 0.9505833333333333\n",
      "Layer 21 accuracy: 0.9508333333333333\n",
      "Layer 22 accuracy: 0.9505\n",
      "Layer 23 accuracy: 0.95075\n",
      "Layer 24 accuracy: 0.9508333333333333\n",
      "Layer 25 accuracy: 0.9510833333333333\n",
      "Layer 26 accuracy: 0.9516666666666667\n",
      "Layer 27 accuracy: 0.9518333333333333\n",
      "Layer 28 accuracy: 0.9519166666666666\n",
      "Layer 29 accuracy: 0.9518333333333333\n",
      "Layer 30 accuracy: 0.9518333333333333\n",
      "Layer 31 accuracy: 0.9518333333333333\n",
      "Layer 32 accuracy: 0.9520833333333333\n",
      "Layer 33 accuracy: 0.9523333333333334\n",
      "Layer 34 accuracy: 0.95225\n",
      "Layer 35 accuracy: 0.9523333333333334\n",
      "Layer 36 accuracy: 0.9524166666666667\n",
      "Layer 37 accuracy: 0.9526666666666667\n",
      "Layer 38 accuracy: 0.9525\n",
      "Layer 39 accuracy: 0.95275\n",
      "Layer 40 accuracy: 0.95275\n",
      "Layer 41 accuracy: 0.9528333333333333\n",
      "Layer 42 accuracy: 0.95275\n",
      "Layer 43 accuracy: 0.9528333333333333\n",
      "Layer 44 accuracy: 0.9528333333333333\n",
      "Layer 45 accuracy: 0.9528333333333333\n",
      "Layer 46 accuracy: 0.953\n",
      "Layer 47 accuracy: 0.9530833333333333\n",
      "Layer 48 accuracy: 0.9530833333333333\n",
      "Layer 49 accuracy: 0.953\n",
      "Layer 50 accuracy: 0.9531666666666667\n",
      "Layer 51 accuracy: 0.9529166666666666\n",
      "Layer 52 accuracy: 0.953\n",
      "Layer 53 accuracy: 0.953\n",
      "Layer 54 accuracy: 0.9529166666666666\n",
      "Layer 55 accuracy: 0.953\n",
      "Layer 56 accuracy: 0.953\n",
      "Layer 57 accuracy: 0.953\n",
      "Layer 58 accuracy: 0.953\n",
      "Layer 59 accuracy: 0.953\n",
      "Layer 60 accuracy: 0.953\n",
      "Layer 61 accuracy: 0.9529166666666666\n",
      "Layer 62 accuracy: 0.953\n",
      "Layer 63 accuracy: 0.9528333333333333\n",
      "Layer 64 accuracy: 0.9529166666666666\n",
      "Layer 65 accuracy: 0.9529166666666666\n",
      "Layer 66 accuracy: 0.953\n",
      "Layer 67 accuracy: 0.9529166666666666\n",
      "Layer 68 accuracy: 0.9529166666666666\n",
      "Layer 69 accuracy: 0.9529166666666666\n",
      "Layer 70 accuracy: 0.9529166666666666\n",
      "Layer 71 accuracy: 0.9529166666666666\n",
      "Layer 72 accuracy: 0.9529166666666666\n",
      "Layer 73 accuracy: 0.9529166666666666\n",
      "Layer 74 accuracy: 0.9529166666666666\n",
      "Layer 75 accuracy: 0.9529166666666666\n",
      "Layer 76 accuracy: 0.9529166666666666\n",
      "Layer 77 accuracy: 0.9529166666666666\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-24b55bc32154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m12000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcascadeForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-c6724a73524b>\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m## verbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6a14400639b4>\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-6a14400639b4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \"\"\"\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "test_x = images[-12000:]\n",
    "test_y = labels[-12000:]\n",
    "cf = cascadeForest(layers)\n",
    "pred, val_acc = cf.predict_proba(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
